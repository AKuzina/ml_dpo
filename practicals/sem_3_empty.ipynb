{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_thAKR27rZY5"
   },
   "source": [
    "# Семинар 3 - linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поработаем с линейной регрессией на практике с помощью библиотеки [scikit-learn](https://scikit-learn.org/stable/). Эта библиотека включает в себя множество алгоритмов, разные тестовые наборов данных, функции для подсчета метрик и подбора параметров, а также многое другое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "Для демонстраций загрузим набор данных [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/Automobile). В данных присутствуют категориальные, целочисленные и вещественнозначные признаки. \n",
    "\n",
    "[Скачаем](https://raw.githubusercontent.com/AKuzina/ml_dpo/main/practicals/automobiles.csv) данные и прочитаем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = pd.read_csv('automobiles.csv', na_values=[\"?\"])\n",
    "X_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1** Создайте отдельно вектор с целевой переменной (столбец `price`) и удалите его из таблицы `X_raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных\n",
    "Предобработка данных важна при применении любых методов машинного обучения, а в особенности для линейных моделей. В sklearn предобработку удобно делать с помощью различных модулей (например, [preprocessing](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)) или методов библиотеки pandas.\n",
    "\n",
    "### Заполнение пропусков\n",
    "В матрице объекты-признаки могут быть пропущенные значения, и это вызовет ошибку при попытке передать такую матрицу в функцию обучения модели или даже предобработки. Если пропусков немного, можно удалить объекты с пропусками из обучающей выборки. Заполнить пропуски можно [разными способами](https://scikit-learn.org/stable/modules/impute.html), например:\n",
    "\n",
    "* заполнить средними (mean, median);\n",
    "* предсказывать пропущенные значения по непропущенным.\n",
    "\n",
    "Последний вариант сложный и применяется редко. Для заполнения константами можно использовать метод датафрейма `fillna`, для замены средними - класс [`impute.SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) (в более старых версиях `scikit-learn` - `preprocessing.Imputer`).\n",
    "\n",
    "Рассмотрим пример его работы (из документации)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.array([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]])\n",
    "array2 = np.array([[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]])\n",
    "\n",
    "print(array1)\n",
    "print(array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нельзя делаять transform до fit\n",
    "imp_mean.transform(array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit посчитает нужные средние по данным\n",
    "imp_mean.fit(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform заполнит посчитанными средними пропущенные значение\n",
    "imp_mean.transform(array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# иногда удобно совмещать оба шага в один\n",
    "imp_mean.fit_transform(array1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Вернемся к нашим данным. Для начала избавимся от наблюдений, у которых пропущена целевая переменная\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.isna().sum())\n",
    "\n",
    "drop_idx = np.where(y.isna())[0]\n",
    "print(drop_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.drop(index = drop_idx, inplace=True)\n",
    "X_raw.drop(index = drop_idx, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2** Посчитайте число пропусков в каждом столбце"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3** Заполните пропуски в данных. Обратите внимание, что `SimpleImputer` возвращает массив, создайте из него `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для удобства работы с нашим датасетом создаем маску, указывающую на столбцы с категориальными признаками\n",
    "cat_features_mask = (X_raw.dtypes == \"object\").values # категориальные признаки имеют тип \"object\"\n",
    "cat_features_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real = X_raw[X_raw.columns[~cat_features_mask]]\n",
    "X_cat = X_raw[X_raw.columns[cat_features_mask]]\n",
    "\n",
    "# для вещественнозначных признаков заполним пропуски средними значениями\n",
    "mis_replacer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# для категориальных - пустыми строками\n",
    "cat_replacer = SimpleImputer(strategy=\"constant\", fill_value=\"\")\n",
    "\n",
    "\n",
    "X_no_nans_real = # your code here\n",
    "X_cat =  # your code here\n",
    "\n",
    "\n",
    "X_no_nans = pd.concat([X_no_nans_real, X_cat], axis=1)\n",
    "X_no_nans.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всегда нужно осознавать, случайны ли пропуски в каком-то признаке. Иногда факт отсутствия информации о значении признака может сам быть важным признаком, который необходимо добавить к другим признакам.\n",
    "\n",
    "__Пример:__ предсказание возраста пользователя по данным с его телефона. Поскольку люди старшего возраста чаще пользуются простыми телефонами, факт отсутствия каких-то данных (например, истории посещенных интернет-страниц), скорее всего, будет хорошим признаком.\n",
    "\n",
    "Для категориальных признаков рекомендуется создавать отдельную категорию, соответствующую пропущенному значению.\n",
    "\n",
    "---\n",
    "### Масштабирование признаков\n",
    "В ходе предобработки данных часто рекомендуется приводить все признаки к одному масштабу. Это важно по нескольким причинам:\n",
    "\n",
    "* ускорение обучения модели;\n",
    "* улучшение численной устойчивости при работе с матрицей объекты-признаки;\n",
    "* для линейных моделей: интерпретация весов при признаках как меры их значимости.\n",
    "\n",
    "(полезная ссылка: https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0)\n",
    "\n",
    "Первый популярный способ масштабирования - нормализация: вычитание среднего из каждого признака и деление на стандартное отклонение ([`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) в sklearn). Второй популярный способ: вычитание минимума из каждого признака, а затем деление на разницу максимального и минимального значения ([`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) в sklearn).\n",
    "\n",
    "**Задание 4** Отмасштабируйте числовые признаки в данных, используя `MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Преобразование нечисловых признаков\n",
    "Практически все методы машинного обучения требуют, чтобы на вход функции обучения подавалась вещественная матрица. В процессе обучения используются свойства вещественных чисел, в частности, возможность сравнения и применения арифметических операций. Поэтому, даже если формально в матрице объекты-признаки записаны числовые значения, нужно всегда анализировать, можно ли относиться к ним как к числам. \n",
    "\n",
    "__Пример:__ некоторые признаки могут задаваться целочисленными хешами или id (например, id пользователя соц. сети), однако нельзя сложить двух пользователей и получить третьего, исходя из их id (как это может сделать линейная модель).\n",
    "\n",
    "К категориальным признакам, принимающим значения из неупорядоченного конечного множества $K$, часто применяют [one-hot encoding](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features) (вместо одного признака создают $K$ бинарных признаков - по одному на каждое возможное значение исходного признака). Правда, нужно понимать, что создание $K$ таких признаков приведет к [мультиколлинеарности](https://ru.wikipedia.org/wiki/%D0%9C%D1%83%D0%BB%D1%8C%D1%82%D0%B8%D0%BA%D0%BE%D0%BB%D0%BB%D0%B8%D0%BD%D0%B5%D0%B0%D1%80%D0%BD%D0%BE%D1%81%D1%82%D1%8C), и поэтому в зависимости от применяемой модели может быть стоит [убрать один из них](https://stats.stackexchange.com/questions/231285/dropping-one-of-the-columns-when-using-one-hot-encoding) (и оставить $K - 1$ признак).\n",
    "\n",
    "В `sklearn` one-hot кодирование можно сделать с помощью класса [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), а можно использовать функцию [`pd.get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html).\n",
    "\n",
    "\n",
    "Следует заметить, что в новой матрице будет очень много нулевых значений. Чтобы не хранить их в памяти, можно задать параметр `OneHotEncoder(sparse=True)` или `.get_dummies(sparse=True)`, и метод вернет [разреженную матрицу](http://docs.scipy.org/doc/scipy/reference/sparse.html), в которой хранятся только ненулевые значения. Выполнение некоторых операций с такой матрицей может быть неэффективным, однако большинство методов sklearn умеют работать с разреженными матрицами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dum = pd.get_dummies(X_no_nans, drop_first=True)\n",
    "print(X_dum.shape)\n",
    "X_dum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__Вопрос__: стоит ли применять one-hot encoding для признаков с большим числом категорий (например, id)? Почему?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо категориальных признаков, преобразования требуют, например, строковые признаки. Их можно превращать в матрицу частот слов с помощью [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), матрицу частот буквосочетаний фиксированной длины, можно извлекать другие признаки (например, длина строки).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление признаков\n",
    "Особенно важным моментом для линейной регрессии является нелинейное преобразование признаков. Это позволяет использовать линейную регрессию для моделирования нелинейных зависимостей. Из популярных преобразований можно выделить следующие: полиномиальные признаки ([`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) в sklearn), взятие логарифма, квадратного корня, применение тригонометрических функий.\n",
    "\n",
    "Например, в нашем датасете зависимость целевой переменной от признака 'curb-weight' скорее квадратичная, чем линейная:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X['curb-weight'], y)\n",
    "plt.xlabel('curb-weight')\n",
    "plt.ylabel('price')\n",
    "plt.grid()\n",
    "plt.show();\n",
    "\n",
    "plt.scatter(X['curb-weight']**2, y)\n",
    "plt.xlabel('(curb-weight)$^2$')\n",
    "plt.ylabel('price')\n",
    "plt.grid()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А для признака `highway-mpg` линеаризовать зависимость получается с помощью функции $\\frac 1 {\\sqrt{\\cdot}}$\n",
    "\n",
    "**Задание 5** Постройте график зависимсти цены от признака `highway-mpg`, преобразованного с помощью функции $\\frac 1 {\\sqrt{\\cdot}}$. Является ли полученная зависимость линейной?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X['highway-mpg'], y)\n",
    "plt.xlabel('highway-mpg')\n",
    "plt.ylabel('price')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что при генерации полиномиальных признаков матрица объекты-признаки может занимать очень много памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия\n",
    "\n",
    "Находится сабмодуле `sklearn.linear_model`. Для обучения обычной модели регрессии с MSE используют класс `LinearRegression()`. Класс `SGDRegressor()` позволяет использовать другие фукции потерь при обучении.\n",
    "\n",
    "Функционал качества в задачах обучения с учителем обычно задается в виде суммы по объектам выборки:\n",
    "$$Q(a, X) = \\frac 1 \\ell \\sum_{i=1}^\\ell L(y_i, a(x_i)),$$\n",
    "где $L(\\cdot, \\cdot)$ - функция потерь, задающая штраф за разницу между предсказанием и истинным значением целевого признака.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# разделим данные на train/test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация модели. На этом этапе задаются все гиперпараметры модели (есть они есть)\n",
    "lr = LinearRegression() \n",
    "\n",
    "# обучение на обучающей выборке (метод `fit`)\n",
    "lr.fit(X_train, y_train) \n",
    "\n",
    "# чтобы сделать прогноз используют метод `predict`\n",
    "y_predicted = lr.predict(X_test) \n",
    "\n",
    "# теперь можно посчитать ошибку на тесте\n",
    "error = np.mean( (y_predicted - y_test)**2 )\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции потерь в регрессии\n",
    "Как отмечалось на первой лекции, функционал качества должен в первую очередь отвечать требованиям заказчика, при этом математические свойства функции потерь могут быть неудобны для оптимизации. \n",
    "\n",
    "### Среднеквадратичная и средняя абсолютная ошибка\n",
    "Кроме требований заказчика, функционал качества должен учитывать математические особенности модели - например, устойчивость к шумовым объектам. В линейной регрессии функция потерь $L(y_i, a(x_i)) = (a(x_i) - y_i)^2$ не обладает этим свойством, потому что задает очень большие штрафы за большие отклонения от фактического значения. \n",
    "\n",
    "Рассмотрим это явление на примере. Предскажем значения признака 'make_audi' по признаку 'engine-size' с помощью линейной регрессии. Добавим к выборке два объекта-выброса и посмотрим, как изменится оптимальная с точки зрения MSE прямая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subset = X[['engine-size']].values\n",
    "y_subset = X[['make_audi']].values\n",
    "\n",
    "# добавление двух шумовых точек\n",
    "X_subset_modified = np.vstack((X_subset, np.array([[1], [2]]))) \n",
    "\n",
    "y_subset_modified = np.vstack((y_subset, np.array([[90], [50]]) )) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Задание 6** Заполните пропуски в фукции, которая обучаеи и визуализирует линейную регрессию с 1 переменной. Запустите ячейку которая рисует графики и обсудите, что вы на них видите. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_MSE(X, y):\n",
    "    # визуализируем точки\n",
    "    plt.scatter(X, y)  \n",
    "    \n",
    "    # обучим линейную модель\n",
    "    # your code here\n",
    "    \n",
    "    # визуализируем прямую\n",
    "    grid = np.linspace(0, 2, 100)\n",
    "    line = lr.predict(grid[:, np.newaxis])\n",
    "    plt.plot(grid, line)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plot_lr_MSE(X_subset, y_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel('engine-size')\n",
    "plt.ylabel('make_audi')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_lr_MSE(X_subset_modified, y_subset_modified)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel('engine-size')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за шумовых объектов прямая достаточно сильно изменила наклон. Поэтому вместо MSE можно использовать Mean Absolute Error: $L(y_i, a(x_i)) = |a(x_i) - y_i|$:\n",
    "\n",
    "Теперь обучим регрессию, оптимизируя MAE. \n",
    "---\n",
    "**Задание 7** Заполните пропуски в фукции, которая обучаеи и визуализирует линейную регрессию с 1 переменной и MAE. Запустите ячейку с построением графиком, прокоментируйте результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_MAE(X, y):\n",
    "    # визуализируем точки\n",
    "    plt.scatter(X, y)   \n",
    "    \n",
    "    # обучим линейную модель с MAE\n",
    "    lr_mae = SGDRegressor(loss='epsilon_insensitive', epsilon=0)\n",
    "    # your code here\n",
    "    \n",
    "    # визуализируем прямую\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_lr_MAE(X_subset, y_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel('engine-size')\n",
    "plt.ylabel('make_audi')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_lr_MAE(X_subset_modified, y_subset_modified)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel('engine-size')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прямая не изменила направление из-за выбросов.\n",
    "\n",
    "Попробуем добавить больше шумовых объектов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "# добавление 30 шумовых точек\n",
    "X_subset_modified_twice = np.vstack((X_subset,  np.random.randint(1, 4, size=30).reshape(-1, 1))) \n",
    "y_subset_modified_twice = np.vstack((y_subset, np.random.randint(30, 100, size=30).reshape(-1, 1))) \n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_lr_MAE(X_subset, y_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel('engine-size')\n",
    "plt.ylabel('make_audi')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_lr_MAE(X_subset_modified_twice, y_subset_modified_twice)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel('engine-size')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прямая изменила наклон, когда мы добавили 30 (почти 15%) шумовых точек.\n",
    "\n",
    "### Huber Loss\n",
    "Иногда используют Huber Loss - \"гибрид\" MAE и MSE, который, как и MAE, устойчив к шумовым объектам, и как и MSE, мало штрафует малые отклонения от фактического значения целевого признака:\n",
    "$$L(y_i, a(x_i)) = \\phi_\\varepsilon(a(x_i) - y_i)$$\n",
    "$$\\phi_\\varepsilon(z) = \\begin{cases} \\frac 1 2 z^2, - \\varepsilon < z < \\varepsilon, \\\\\\varepsilon (|z| - \\frac 1 2 \\varepsilon), иначе \\\\ \\end{cases}$$\n",
    "\n",
    "Оптимизация Huber Loss реализована в sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "# or\n",
    "# SGDRegressor(loss='huber')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 8** Обучите линейную регрессию с HuberLoss (используя все доступные признаки и целевую переменную price). Посчитайте ошибку на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация модели. На этом этапе задаются все гиперпараметры модели (есть они есть)\n",
    "\n",
    "\n",
    "# обучение на обучающей выборке (метод `fit`)\n",
    "\n",
    "\n",
    "# чтобы сделать прогноз используют метод `predict`\n",
    "\n",
    "\n",
    "# теперь можно посчитать ошибку на тесте\n",
    "\n",
    "print('Error with Huber Loss', error_huber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Сравним три рассмотренные функции потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(-3, 3, 100)\n",
    "quantile_tau = 0.2\n",
    "mse_loss = grid ** 2\n",
    "mae_loss = np.abs(grid)\n",
    "huber_loss = 0.5 * mse_loss * (grid >= -1) * (grid <= 1) + (mae_loss - 0.5) * (grid < -1) + (mae_loss - 0.5)  * (grid > 1)\n",
    "\n",
    "plt.plot(grid, mae_loss, label=\"Absolute Loss\")\n",
    "plt.plot(grid, mse_loss, label=\"Quadratic Loss\")\n",
    "plt.plot(grid, huber_loss, label=\"Huber Loss\")\n",
    "\n",
    "plt.xlabel(\"$y_i - a(x_i)$\")\n",
    "plt.ylabel(\"$L(y_i, a(x_i))$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso and Ridge \n",
    "\n",
    "Вернемся к нашей задаче предсказания цены. Обучим тепель линейную регрессию с $L_1$ и $L_2$ регуляризациями. Обе модели находятся сабмодуле `sklearn.linear_model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомним, как выглядит функционал для обучения Lasso:\n",
    "$$\n",
    "\\frac{1}{l}\\|X w - y\\|^2  + \\lambda \\sum_{i=1}^d|w_i| \\rightarrow \\min_w\n",
    "$$\n",
    "\n",
    "$\\lambda $ - гиперпараметр, в `sklearn` для его обозначения чаще всего используется аргумент `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model and set the hyperparameters\n",
    "lasso = Lasso(alpha=1)\n",
    "\n",
    "# train\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# predict \n",
    "y_predicted = lasso.predict(X_test) \n",
    "\n",
    "\n",
    "print('Error', np.mean( (y_predicted - y_test)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model and set the hyperparameters\n",
    "ridge = Ridge(alpha=1)\n",
    "\n",
    "# train\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# predict \n",
    "y_predicted = ridge.predict(X_test) \n",
    "\n",
    "\n",
    "print('Error', np.mean( (y_predicted - y_test)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__Вопрос__: можно ли я сравнивать ошибку на тесте для разных моделей и на ее основании выбирать лучшую?\n",
    "\n",
    "---\n",
    "\n",
    "![im](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `cross_val_score` имеет следующие аргументы:\n",
    " - estimator (model or the whole pipeline)\n",
    " - training data\n",
    " - количество фолдов\n",
    " - метрика качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible scorers\n",
    "import sklearn.metrics\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = cross_val_score(estimator=lasso, X=X_train, y=y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CV score for lasso: {:.2f}'.format(np.mean(cv_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 9** Используя `cross_val_score` сравните \n",
    "- Линейную регрессию с MSE\n",
    "- Линейную регрессию с Huber Loss\n",
    "- Lasso регрессию \n",
    "- Ridge регрессию \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 9** Для лучшей модели посчитайтк RMSE (Root Mean Squared Error) на тестовых данных. Проинтерпритируйте результат.\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac1l\\sum_{i=1}^l(y_1 - \\hat{y}_i)}, \\quad \\hat{y}_i - \\text{предсказанное моделью значение целевой переменной}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "wBrx6KM0rZZH"
   ],
   "name": "sem01_empty.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "BASE_ENV",
   "language": "python",
   "name": "base_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
