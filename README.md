
Преподаватели: [Аня Кузина](https://akuzina.github.io/), [Евгений Егоров](https://evgenii-egorov.github.io/)

[Чат](https://t.me/joinchat/CzqJzE94b6QN6Oe9FQ-b9w) с менеджерами и преподавателями

## Материалы

| Дата | Тема | Лекция | Практика| Практика (решения) |
|-----|-----|----------|---------|-------------|
|12 дек|Введение и основные задачи| [Lecture 1](lectures/Lecture1_intro.pdf) | [Seminar 1](practicals/sem_1_empty.ipynb) | [Seminar 1](practicals/sem_1_full.ipynb) |
|19 дек|Линейная регрессия| [Lecture 2](lectures/Lecture2_lr.pdf) | [Seminar 2](practicals/sem_2_empty.ipynb) | [Seminar 2](practicals/sem_2_full.ipynb)| 
|26 дек|Градиентные методы обучения| [Lecture 3](lectures/Lecture3_gd.pdf) | [Seminar 3](practicals/sem_3_empty.ipynb) |[Seminar 3](practicals/sem_3_full.ipynb)| 
|16 янв|Линейная классификация и метрики качества классификации|  [Lecture 4](lectures/Lecture4-linclass.pdf) |[Seminar 4](practicals/sem_4_empty.ipynb)|[Seminar 4](practicals/sem_4_full.ipynb)|
|23 янв|Логистическая регрессия и SVM|[Lecture 5](lectures/Lecture5_svm.pdf) |[Seminar 5](practicals/sem_5_empty.ipynb)|[Seminar 5](practicals/sem_5_full.ipynb)|
|30 янв|Многоклассовая классификация, работа с категориальными признаками и текстами|  [Lecture 6](lectures/Lecture6-multiclass.pdf) |[Seminar 6](practicals/sem_6_empty.ipynb)||
|06 фев|Решающие деревья|[Lecture 7](lectures/Lecture7_trees.pdf)| [Seminar 7](practicals/sem_7_empty.ipynb)|[Seminar 7](practicals/sem_7_full.ipynb)|
|13 фев|Бэггинг и случайные леса|[Lecture 8](lectures/Lecture8_ensembles.pdf)||[Seminar 8](practicals/sem_8_full.ipynb)|
|27 фев|Градиентный бустинг|[Lecture 9](lectures/Lecture9_gradboost.pdf)||[Seminar 9](practicals/sem_9_full.ipynb)|
|13 мар|Градиентный бустинг: имплементации|[Lecture 10](lectures/Lecture10_gb_part2.pdf)| [Seminar 10](practicals/sem_10_empty.ipynb)|[Seminar 10](practicals/sem_10_full.ipynb)|
|20 мар|Отбор признаков и понижение размерности|[Lecture 11](lectures/Lecture11_dim_red.pdf)| [Seminar 11](practicals/sem_11_empty.ipynb)|[Seminar 11](practicals/sem_11_full.ipynb)|
|27 мар|Кластеризация|[Lecture 12](lectures/Lecture12_cluster.pdf)||[Seminar 12](practicals/sem_12_full.ipynb)|
|03 апр|Поиск аномалий|[Lecture 13](lectures/Lecture13_anomaly.pdf)|[Seminar 13](practicals/sem_13_empty.ipynb)|[Seminar 13](practicals/sem_13_full.ipynb)|
|10 апр|Рекомендательные системы||||
|17 апр|Ранжирование|[Lecture 15](lectures/Lecture15_ranking.pdf)|[Seminar 15](practicals/sem_15_empty.ipynb)|[Seminar 15](practicals/sem_15_full.ipynb)|
|24 апр|Заключение||||


## Домашние задания
Ссылка на курс в Anytask: https://anytask.org/course/770

Инвайт: `UrcWPXY`


| Дата публикации| Задание | Дедлайн | Формат Сдачи|
|----------------|---------|---------|-------------|
| 19.12.2020     |[HW 1](https://github.com/AKuzina/ml_dpo/tree/main/hw/hw1)| 31.12.2020 23:30| Загрузить ноутбук в Anytask|
| 27.12.2020     |[HW 2](https://github.com/AKuzina/ml_dpo/tree/main/hw/hw2)| 17.01.2021 23:59| Загрузить ноутбук в Anytask|
| 27.01.2021     |[HW 3](https://github.com/AKuzina/ml_dpo/tree/main/hw/hw3)| 11.02.2021 23:30 | Загрузить ноутбук в Anytask|
| 20.02.2021     |[HW 4](https://github.com/AKuzina/ml_dpo/tree/main/hw/hw4)| 07.03.2021 23:30 | Загрузить ноутбук в Anytask|
| 2.04.2021     |[HW 5](https://github.com/AKuzina/ml_dpo/tree/main/hw/hw5)| 16.04.2021 23:30 | Загрузить ноутбук в Anytask|


## Полезные ссылки
Disclaimer: ниже представлены ссылки на полезные или просто красивые ресурсы по теме, 
многие из них на английском языке и не обязательны для успешного прохождения курса. 

### Python
[Python tutorial from Stanford](https://cs231n.github.io/python-numpy-tutorial/)

[Numpy Tutorial from Datacamp](https://www.datacamp.com/community/tutorials/python-numpy-tutorial)

[Visual Numpy](http://jalammar.github.io/visual-numpy/)

[Pyplot tutorial](https://matplotlib.org/tutorials/introductory/pyplot.html)

[Matplotlib gallery](https://matplotlib.org/gallery.html)

### Machine Learning
[ML playground](https://ml-playground.com/)

[Visual Introduction to ML](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)

[Begginer's Guide to dimensionality reduction](https://idyll.pub/post/dimensionality-reduction-293e465c2a3443e8941b016d/)

[Bias-variance trade-off](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)

[Курс по МО](https://github.com/esokolov/ml-course-hse), который читается на ПМИ